# Home-LLM-Server-Guide-RU

## 1. Установка LLM 

Есть 2 пути для взаимодействия с моделью через endpoint-ы:
1. LM Studio.
2. Свой сервис-wrapper над LLAMA.cpp.
В каждом из путей необходимо установить GGUF модель одним файлом.
## 1. Взаимодействие между домашним стендом и сервером
1. OpenSSH

При использовании LM Studio с его endpint-ами нельзя напрямую перенаправлять порт, для этого необходимо [запустить велосипед](HOME-PC/main.go) на домашнем стенде для перенаправления порта, а также развернуть p2p подключение с сервером при помощи
```
ssh -R port-output-server:localhost:port-input-llm-or-proxy-script user-name@server-ip
```
для отладки можно использовать `-v`

2. OpenVPN or WireGuard
   
**todo**

## 3. Взаимодействие между сервером и стендом
Запускаем прокси-сервер, также [незабываем поменять ключ аутентификации чтобы вашим сервером не начала пользоваться добрая половина Китая и Бразилии](SERVER/main.go)